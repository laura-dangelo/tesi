% !TeX root = ../Thesis.tex
% Chapter 4
%======================================================================
\chapter*{Conclusions} % Write in your own chapter title
\label{ch5}
\setlength{\parskip}{0.5pt}

%\fancyhead[RO,LE]{\thepage}
%\fancyhead[LO]{\emph{Conclusions}}
%\fancyhead[RE]{\emph{\Sectionname}}

%\lhead{\emph{Conclusions}}
\addcontentsline{toc}{chapter}{Conclusions}
%======================================================================

%======================================================================
\section*{Discussion}

In recent years the technological advances have enabled the collection of increasingly complex data. Calcium imaging data fit perfectly into this context: being high dimensional, often collected in elaborate experimental settings, with spatial and temporal dependence structures, and with a non-homogeneous response between neurons, they present several modeling challenges.
Analyzing these data hence fosters investigation of new statistical and computational tools in many directions.
In this thesis, we have examined three different, although related, aspects of a Bayesian analysis of these data.

In the first chapter, we have considered a classical two-stage approach, based on a first deconvolution phase and a successive statistical analysis of the output. Specifically, we have examined the use of Poisson regression models to relate the number of detected spikes with several covariates describing the experimental conditions. 
However, although we focused on this specific application, Poisson log-linear models are routinely used in many contexts, making our work applicable also outside of the scope of calcium imaging studies.
We have developed two Markov chain Monte Carlo algorithms to sample from the posterior distribution of the regression parameters under the assumption of conditionally Gaussian prior distributions.
The algorithms exploit the introduction of an approximate posterior distribution, which is used as the building block for a Metropolis-Hastings and importance sampling algorithms. 
The proposed sampling strategies show good performances in terms of efficiency compared to state-of-the-art methods.

In the second chapter, we have developed a nonparametric nested mixture model that allows for simultaneous deconvolution and estimation of the spiking activity, hence overcoming standard two-stage approaches.
The model makes use of two nested layers of random discrete mixture priors to borrow information between experiments and discover similarities in the neuronal response to different types of stimuli. 
If, on the one hand, the Bayesian approach is computationally less efficient than routinely used methods, on the other hand, the possibility to define a flexible prior distribution was key to including knowledge on the structure of the data, and hence to fully exploit the available information. 
The results on simulated data show how simultaneous deconvolution and estimation of the spike amplitudes leads to lower misclassification error, thanks to the borrowing of information between the two phases. Application to a real data set from the Allen Brain Observatory demonstrates the ability to capture characteristic features of neuronal activity.

Finally, in the last chapter, we have moved to the multivariate analysis of populations of neurons. In general, neurons do not exhibit a homogeneous response to stimulation, and a relevant research question in neuroscience is studying groups of co-activating cells.
This motivated the investigation of new clustering strategies to identify calcium traces with a similar underlying pattern of activity over seconds-long periods of time.
We have formulated a nonparametric mixture model that deconvolves the fluorescence traces and clusters the latent binary series of activity. The latter task is achieved through the introduction of a latent continuous process that explicitly characterizes the spike probabilities and models their temporal dependence. Moreover, spatial dependence is also taken into account by using location-dependent mixture weights. Similarly to Chapter 3, also here adopting a Bayesian approach led to a substantial improvement in the characterization the structure of the data. Standard methods to perform clustering of neurons, based on summary statistics of the data, necessarily involve loss of information, which can instead be exploited in the analysis thanks to the construction of adequate prior distributions.

%======================================================================
\section*{Future directions of research}

The work described in Chapter 4 presents some aspects that are prone to possible extensions and improvements, some of which have already been described in the dedicated sections. A first issue, already raised in Sec.~\ref{ch4:sec_sim}, is related to the computational cost of the algorithm used to perform posterior inference. To estimate the realizations of the latent mixture of Gaussian process, we applied the particle filtering algorithm proposed by \textcite{fasano2021}. Although the algorithm is a very good strategy to perform inference on binary state space models, it is not the most appropriate method in our context, as it must be run at every iteration of the Gibbs sampler. Hence, it would be useful to devise computationally more efficient ways to sample the realizations of the latent mixture of Gaussian processes.

The process on the amplitudes is very simple and somehow restrictive: as already discussed, it would be useful to replace the gamma prior with a more flexible distribution such as, for example, a mixture prior, similarly to Chapter 3.

Another possible improvement is relative to the time window used in the application to the hippocampal neurons data. As already pointed out, the choice of the time window can heavily affect the resulting clustering and hence the implications of the findings. Moreover, one could choose between segmenting the series or opting for a sliding window approach. All these issues are worth additional research, and, in particular, it would be useful to develop some methods to evaluate the sensitivity of the clustering to the different alternatives, and, possibly, to provide a way to evaluate what choice led to the ``best'' results.

In the hippocampal neurons data set it is also available an additional covariate that at each time records the spatial coordinates of the mouse into the environment. It would be interesting to conduct further research to extend the model of Chapter 4 to include this information. To model dependence of the spiking activity from this covariate, one possibility could be to divide the environment into quadrants, and adopt the nested mixture of Chapter 3 by considering each quadrant as a different experimental condition.
Another possibility could be to represent the movements of the mouse using a network structure. A regression model could then be defined to relate the neurons' activity at each time point with the mouse's location by using a prior distribution on graphs~\parencite{cai2019}. 



