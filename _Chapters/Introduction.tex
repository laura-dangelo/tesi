\addchap{Introduction}
%\addcontentsline{toc}{chapter}{Introduction}
%\chapter*{Introduction} 


\addcontentsline{toc}{section}{Overview}
\section*{Overview}

A fundamental but unsolved problem in neuroscience is understanding the functioning of neurons and neuronal networks in processing sensory information, generating locomotion, and mediating learning and memory.
The investigation of the structure and function of the nervous system can be dated back to the nineteenth century with the invention of the technique of silver impregnation by Camillo Golgi in 1873, which allowed the visualization of individual neurons~\parencite{drouin2015}. The technique initiated the study of the microscopic anatomy of the nervous system, and the investigation of how neurons organize to form the brain. 
Ever since there has been a significant research effort both to discover the cellular properties of the nervous system, and to characterize behaviors and correlate them with activity imaged in different regions of the brain.
However, many scientists recognize that despite the innovative techniques developed to observe and analyze neurons, we are still facing an ``explanatory gap'' between the understanding of elemental components and the outputs that they produce~\parencite{parker2006,parker2010,dudai2004}. That is, we know a lot about the components of the nervous system, but still we have little insight into how these components work together to enable us to think, remember, or behave. One of the reasons of this gap is the availability of a huge quantity of data, but a lack of tools to integrate these data in order to obtain a coherent picture of the brain functioning~\parencite{parker2010}.

The technological developments of the last few decades have opened fundamentally new opportunities to investigate the nervous system. Large neuronal networks can now be visualized using \textit{in vivo} high-resolution imaging techniques, which permit to record the neuronal activity in freely moving animals over long periods of time. In this thesis, we focus on data resulting from the application of the two-photon calcium imaging technique. Calcium ions generate intracellular signals that determine a large variety of functions in all neurons: when a neuron fires, calcium floods the cell and produces a transient spike in its concentration~\parencite{grienberger2012}. By using genetically encoded calcium indicators, which are fluorescent molecules that react when binding to the calcium ions, it is possible to optically measure the level of calcium by analyzing the observed fluorescence trace. 
However, extracting these fluorescent calcium traces is just the first step towards the understanding of brain circuits: how to relate the observed pattern of neuronal activity to the external stimuli that triggered it remains an open problem of research. 

The first step for analyzing fluorescent calcium traces is to deconvolve them to extract the spike trains, which are the series of recorded firing times and spikes' amplitudes.
From these series it is possible to derive many useful quantities which are commonly used to interpret the neuron's activity: for example, one can compute the number of recorded firing events, neuron-specific or stimulus-specific distributions of the spikes' amplitudes, and other proxies of the intensity of the neuronal response.
The set of tools that explicitly try to relate external stimuli with some summary of activity are usually referred to as ``encoding models''. In this context the stimuli are considered as features, and they are used to predict patterns of neuronal activity. These models allow to investigate how experimental conditions and specific stimulation trigger the neurons' activity, and hence how external information is encoded by individual neurons and neuronal networks.



\addcontentsline{toc}{section}{Main contributions of the thesis}
\section*{Main contributions of the thesis}
The availability of large quantities of data from calcium imaging studies, and the relative scarcity of tools to analyze them motivated the investigation of new methodologies.
In this thesis, we aim to contribute to the development of novel statistical tools to gain new insights into the analysis of calcium imaging data.
Herein, we adopted a Bayesian approach: there are several reasons that led to this choice. As it will become clearer from the details of the specific applications, a Bayesian approach had proved necessary in order to deal with models that comprised complex dependency structures, heterogeneous data, and, possibly, the availability of past information from previous studies. Moreover, using a Bayesian approach, it is straightforward to induce some regularization on the model parameters, a feature that is often fundamental in multivariate studies.

\subsubsection{Novel posterior sampling scheme for Poisson encoding models}
Linear models and generalized linear models are among the most natural classes of encoding models~\parencite{paninski2007}. They allow to link the observed output of an experiment with a number of features and experimental conditions in a flexible and interpretable way. In particular, if the variable of interest is the number of spikes, which is a proxy of the intensity of the neuronal response, Poisson regression represents a straightforward choice. However, the dimensionality of the considered data poses a computational challenge and leads to the need for efficient algorithms to obtain a sample from the posterior distribution of parameters. 
Motivated by the lack of specific and efficient algorithms to sample from the posterior distribution of the parameters
of Bayesian log-linear models, in Chapter 2 we develop a novel sampling strategy which exhibits superior performance with respect to the state-of-the-art alternatives. 

In particular, we develop an efficient Metropolis-Hastings algorithm and importance sampler to simulate from the posterior distribution of the regression parameters.
The key for both algorithms is the introduction of a proposal density based on an approximation of the posterior distribution of parameters under conditional Gaussian priors. 
With conditional Gaussian prior, we refer to a possibly hierarchical prior with conditional distribution $\beta \sim \mathrm{N}(b, B)$, with $b$ and/or $B$ random. Examples include straightforward Gaussian prior distributions with informative $(b,B)$ fixed using prior information, and scale mixtures of Gaussian where $b$ is set to zero and the variance has a suitable hierarchical representation, such as the Bayesian lasso prior or the horseshoe prior, among others.
Our result leverages the negative binomial convergence to
the Poisson likelihood \parencite{casella2002}: thanks to this result, we are able to exploit the P\'olya-gamma data augmentation of~\textcite{polson_scott_2013} to derive an efficient sampling scheme. 

The performances of the proposed solutions, in terms of mixing and computation time, are comparable or superior to those of the efficient Stan implementation of the Hamiltonian Monte Carlo algorithm in all scenarios considered in an extensive simulation study, and particularly when a hierarchical prior is assumed. 
The ease of application of the proposed algorithms is further enhanced by their availability via the R package \texttt{bpr} \parencite{bpr}. Clearly, the impact is broader than the motivating application to calcium imaging data, as Poisson regression is commonly used in several other fields.


\subsubsection{Modeling single-neuron activations via nonparametric mixtures}
Routine methods to analyze calcium imaging data are based on a two-stage approach: in a first phase, the raw fluorescent trace is deconvolved to extract the spike train, then, in a second phase, some summary statistics is derived and linked to the experimental conditions that generated it. 
This approach, adopted in the previous contribution, is simple to implement and can be applied in a broad range of applications, however, it has some drawbacks: for example, the impossibility to borrow information between the two stages, and an unclear quantification of the uncertainty propagating from one stage to the next. Only performing the two tasks simultaneously allows to coherently quantify the uncertainty of the results, whereas, in a two-step approach, it is not straightforward to evaluate the overall uncertainty, as it is the result of the contribution of each step. 

In Chapter 3, we introduce a nested Bayesian finite mixture model that allows for estimating the spiking activity and, simultaneously, reconstructing the distributions of the calcium transient spikes' amplitudes under different experimental conditions, for example, in response to different types of stimuli.
More specifically, our modeling framework estimates and clusters the distributions of the calcium transient spikes’ amplitudes via a nested formulation of the generalized mixtures of finite mixtures prior recently proposed by~\textcite{fruhwirthschnatter2020}. The proposed model further adopts the use of a common atom specification as in~\textcite{denti2021} for estimating the distribution of the spikes’ amplitudes under each experimental condition. 
These two nested layers of random discrete mixture priors allow to borrow information between experiments and discover similarities in the distributional patterns of neuronal responses to different stimuli. Furthermore, the spikes’ intensity values are also clustered within and between experimental conditions to determine the existence of common (recurring) response amplitudes.




\subsubsection{Clustering activation patterns of spatially-referenced neurons}
When analyzing populations of neurons, often the interest is in identifying groups of neurons with a highly correlated pattern of activity. For many areas of the brain, there is a general agreement on the organization of these networks of neurons and their behavior.
However, the functional and anatomical organization of hippocampal neurons is still an open research problem. 

In Chapter 4, we formulate a nonparametric mixture model that allows for deconvolution of several calcium traces and, simultaneously, detection of groups of co-activating neurons.
Specifically, our model clusters the latent binary time series of activity based on similarities of the spiking activity over seconds-long periods of time. 
The model makes use of a latent continuous process for the spike probabilities to identify groups of co-activating cells. Neurons' dependence is taken into account by informing the mixture weights with their spatial location through the use of a probit stick breaking process~\parencite{rodriguez2011}, following the common neuroscience assumption that neighboring neurons often activate together. 











