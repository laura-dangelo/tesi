% Chapter 1
\chapter{Background: statistical modeling of calcium imaging data}
\fancyhead[RO,LE]{\thepage}
\fancyhead[LO]{Chapter 1 - \emph{Background}}
\fancyhead[RE]{Section \thesection \ - \emph{\Sectionname}}

\setlength{\parskip}{0.5pt}

\bigskip

\section{Overview of calcium imaging data} 

Calcium ions generate intracellular signals that control key functions in all types of neurons.
At rest, most neurons have an intracellular calcium concentration of about 100 nm; however, during electrical activity, the concentration can rise transiently up to levels around 1000 nm~\citep{berridge2000}. 
The development of techniques that enable the visualization and quantitative estimation of the intracellular calcium signals have thus greatly enhanced the investigation of neuronal functioning.
The development of calcium imaging techniques involved two parallel processes: the development of calcium indicators, which are fluorescent molecules that react when binding to the calcium ions, and the implementation of the appropriate imaging instrumentation, in particular, the introduction of two-photon microscopy~\citep{denk1990}.
In recent years, the innovation achieved in these two fields has allowed for real-time observation of biological processes at the single-cell level simultaneously for large groups of neurons~\citep{grienberger2012}. 

The output two-photon calcium imaging is a movie of time-varying fluorescence intensities, and a first complex pre-processing phase deals with the identification of the spatial location of each neuron in the optical field and source extraction~\citep{mukamel2009,dombeck2010}. The resulting processed data consist of a fluorescent calcium trace for each observable neuron in the targeted area which, however, is only a proxy of the underlying neuronal activity.
Hence further analyses are needed to deconvolve the fluorescence trace to extract the spike train (i.e. the series of recorded firing times), and to try to explain how these firing events are linked with the experiment that generated that particular pattern of activity.

\subsection{Deconvolution methods}

There is currently a rich literature of methods addressing the issue of deconvolving the raw fluorescent trace to extract the spike train. A successful approach is to assume a biophysical model to relate the spiking activity to the calcium dynamics, and to the observed fluorescence. \citet{vogelstein2010} proposed a simple but effective model that has later been adopted by several authors~\citep{pnevmatikakis2016, friedrich2016, friedrich2017, jewell2018, jewell2019}. The model considers the observed fluorescence as a linear (and noisy) function of the intracellular calcium concentration; the calcium dynamics is then modeled using an autoregressive process with jumps in correspondence of the neuron's firing events.
Denoting with $y_t$ the observed fluorescence trace of a neuron and with $c_t$ the underlying calcium concentration, for time $t=1,\dots,T$, the model can be written as
\begin{equation}
\begin{gathered}
y_t = b + c_t + \epsilon_t,\quad \epsilon_t \sim \mathrm{N}(0,\sigma^2),  \\
c_t = \gamma\, c_{t-1} + A_t + w_t, \quad w_t \sim \mathrm{N}(0, \tau^2),
\end{gathered}
\label{eq:ch1_armodel}
\end{equation}
where $b$ models the baseline level of the observed trace and $\epsilon_t$ is a Gaussian measurement error. In the absence of neuronal activity, the true calcium concentration $c_t$ is considered to be centered around zero. The parameter $A_t$ captures the neuronal activity: in the absence of a spike ($A_t = 0$), the calcium level follows a AR(1) process controlled by the parameter $\gamma$; when a spike occurs, the concentration increases instantaneously of a value $A_t > 0$.
A challenge remains estimating the neuronal activity $A_t$ in a precise and computationally efficient way.

\citet{vogelstein2010} assume that all spikes have a fixed amplitude, and interpret the parameter $A_t$ as the \textit{number} of spikes at time $t$. Following this definition, they place a Poisson prior distribution on $A_t$; however, the maximum a posteriori estimation of the spike train using a Poisson distribution is computationally intractable. Hence they search an approximate solution by replacing the Poisson distribution with an exponential distribution of the same mean. This leads to some loss of interpretation of the parameters $A_t$, as now they are no longer integer values but rather non-negative real numbers, but turns the problem into a convex optimization, which can be solved efficiently.
Adopting this approach leads to solving a non-negative lasso problem for estimating the calcium concentration, where the $L_1$ penalty enforces sparsity of the neural activity.
Efficient algorithms to obtain a solution of this problem were also proposed by \citet{pnevmatikakis2016}, \citet{friedrich2016}, and \citet{friedrich2017}.

A different perspective is instead proposed by~\citet{jewell2018} and~\citet{jewell2019}: rather than interpreting $A_t$ in model~(\ref{eq:ch1_armodel}) as the number of spikes at the $t$-th timestep, they interpret its sign as an indicator for whether or not \textit{at least one} spike occurred, that is, $A_t = 0$ indicates no spikes at time $t$, and $A_t>0$ indicates the occurrence of at least one spike. The model so formulated includes an indicator variable, which corresponds to using an $L_0$ penalization and which makes the optimization problem highly non-convex. 
In their work, \citet{jewell2018} and~\citet{jewell2019} develop fast algorithms to compute the spike trains under these assumptions.
\citet{jewell2018} assert that the solutions discussed by \citet{vogelstein2010}, \citet{friedrich2016}, and \citet{friedrich2017} can actually be seen as convex relaxations of this optimization problem, to overcome the computational intractability of the $L_0$ penalization. 

Finally,~\citet{pnevmatikakis2013} propose a fully Bayesian approach. Although less computationally efficient than optimization methods, it allows to obtain a posterior distribution of all model parameters instead of just a point estimate, hence improving uncertainty quantification.
Differently from previous models, they define the parameter $A_t$ as the \textit{amplitude} of a spike at time $t$, taking values in the non-negative real numbers.
They formulate the presence/absence of a spike and its amplitude by using the product of a Bernoulli random variable (taking value 0 if there is no spike at time $t$, and 1 otherwise) with a half-Gaussian random variable (modeling the positive amplitudes). However, they do not explicitly assume sparsity of the spikes.

\section{Data sets} 
Una frase introduttiva? Parlo dei dati dell'Allen Brain Observatory e poi ci sarebbe da mettere i nuovi dati se riesco a fare qualcosa del progetto 3...

\subsection{Allen Brain Observatory data}
The Allen Brain Observatory~\citep{allen} is a public large data repository for investigating how sensory stimulation is represented by neural activity in the mouse visual cortex in both single cells and populations.
The project aims to provide a standardized and systematic survey to measure and analyze visual responses from neurons across cortical areas and layers, utilizing transgenic Cre lines to drive expression of genetically encoded fluorescent calcium indicators, and measured by \textit{in vivo} two-photon calcium imaging.

The study is an extended survey of physiological activity in the mouse visual cortex in response to a range of visual stimuli~\citep{allen_stimulus}. Each mouse is placed in front of a screen where different types of visual stimuli are shown, while the mouseâ€™s neuronal activity is recorded. The stimuli vary from simple synthetic images such as locally sparse noise or static gratings, to complex natural scenes and movies.
The goal of the study is to investigate how neurons at different depths in the visual areas respond to stimuli of different complexity. Specifically, each neuron in the visual cortex can be characterized by their \textit{receptive field}, i.e. the features of the visual stimulus that trigger the signaling of that neuron. Hence, it is of critical interest to devise methods that allow inferring how the neuronal response varies under the different types of visual stimuli. %We expect that the neuronal activity will vary across all the experimental settings, and that some variations in its intensity will be observed based on the specific visual stimulus.


\subsection{Altri dati?}
Paragrafo qui.

\section{A brief review of some Bayesian nonparametric models} 
In this section we review some statistical tools that will be employed in this thesis in the analysis of calcium imaging data. The purpose of this section is not to provide a comprehensive review, but rather to outline the theoretical framework we adopted and fix some notation.
The core topic will be the Bayesian methodology, with a focus on Bayesian nonparametric models.

\subsection{Finite mixture models}
We start our discussion by reviewing finite mixtures. Although they are not part of the Bayesian nonparametric methodology, they provide the starting point for many models that we will review in the following. This brief overview of finite mixtures is largely based on the dedicated chapter in~\citet{gelman2013}.

Mixtures are a popular tool to model heterogeneous data, characterized by the presence of subpopulations within the overall population. In many practical problems the data are collected under different conditions -- unfortunately, it is not always possible to have information on the subpopulation to which each individual observation belongs.
Mixture models can be used in problems of this type, where the population consists of a number of latent subpopulations, within each of which a relatively simple model can be applied.

Denote the observed data as a vector of $n$ units $\bm{y} = (y_1,\dots,y_n)$; also, assume that the $n$ observations are exchangeable, meaning that the joint probability density $p(y_1,\dots,y_n)$ is invariant to permutations of the indices. In the framework of finite mixtures, we assume that the population is made of $K\leq n$ subpopulations, with $K$ known and fixed.
We assume that within each of these groups, the distribution of $y_i$, $i=1,\dots,n$, can be modeled as $f(y_i \mid \theta_k)$, for $k=1,\dots,K$. Usually a common parametric family is assumed for all these component distributions, which however depend on specific parameter vectors $\theta_k$.
The last missing piece to construct a mixture model is the parameter describing the proportion of population from each component $k$: we denote this parameter with $\pi_k$, satisfying $\sum_{k=1}^K \pi_k = 1$. Denoting the full vectors of parameters as $\bm{\theta} = (\theta_1,\dots,\theta_K)$ and $\bm{\pi} = (\pi_1,\dots,\pi_K)$, the data distribution for observation $i$ can be formulated as
\begin{equation*}
p(y_i\mid \bm{\theta},\bm{\pi}) = \pi_1 \, f(y_i\mid\theta_1) + \dots + \pi_K \, f(y_i\mid\theta_K).
\end{equation*}

In mixture models it is convenient to think of the component indicators as missing data, and to impute them so that the model closely resembles a hierarchical model. Hence we introduce the indicator $S_{ik}$ of component $k$ for observation $i$, with 
\begin{equation*}
S_{ik} = \begin{cases}
1 \quad \text{if $y_i$ is drawn from component $k$}\\
0 \quad \text{otherwise}.
\end{cases}
\end{equation*}
Given $\bm{\pi}$, the distribution of $\bm{S}_i = (S_{i1},\dots,S_{iK})$ is $\mathrm{Multinomial}(1;\pi_1,\dots,\pi_K)$. 
Conditionally on $\bm{S}_{i}$, the data distribution of $y_i$ is simply $p(y_i\mid \bm{S}_i,\bm{\theta}) = \prod_{k=1}^K f(y_i\mid\theta_k)^{S_{ik}}$; moreover, given $\bm{S}=(\bm{S}_1,\dots,\bm{S}_n)$, the $y_i$ are assumed to be independent.
Introducing these allocation variables thus greatly simplifies the data distribution: the joint density of the observed data and the unobserved indicators, conditionally on the model parameters, can now be written as 
\begin{equation*}
p(\bm{y},\bm{S}\mid \bm{\theta},\bm{\pi}) = p(\bm{y}\mid\bm{S},\bm{\theta})\, p(\bm{S}\mid\bm{\pi}) = 
\prod_{i=1}^n \prod_{k=1}^K \left\{ \pi_k f(y_i\mid\theta_k) \right\}^{S_{ik}}.
\end{equation*}

Having defined the data distribution, we need to specify adequate prior distributions on the model parameters $\bm{\pi}$ and $\bm{\theta}$. The prior on $\bm{\theta}$ is usually chosen depending on the specific application and on the basis of the component distribution $f$. For the mixture proportions $\pi_k$, the conjugate and most natural prior distribution is the Dirichlet distribution, $\bm{\pi}\sim \mathrm{Dir}(\alpha_1,\dots,\alpha_K)$.





\subsection{Dirichlet process mixtures}


\subsection{Mixtures of finite mixtures}


\subsection{Bayesian nonparametric models for nested data}
















